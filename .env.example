# Qwen3 TTS FastAPI Environment Configuration
# Copy this file to .env and customize as needed

# ============================================
# Server Settings
# ============================================
HOST=127.0.0.1
PORT=8000

# Logging level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
# DEBUG = verbose logging for troubleshooting
# INFO = standard operational logging
# WARNING = only warnings and errors
LOG_LEVEL=INFO

# ============================================
# Model Manager Settings
# ============================================

# Seconds before unloading idle models from VRAM
# Default: 600 (10 minutes)
# Recommendation:
#   - Development: 60 (1 minute - quick cleanup)
#   - Production: 600 (10 minutes - keep hot models loaded)
IDLE_TIMEOUT=600

# Default device for model loading
# Options: cuda, cpu
# Default: cuda
DEFAULT_DEVICE=cuda

# Attention Backend Settings
# Attention implementation backend
# Options: auto, eager, sdpa, flash_attention_2
# Default: auto (auto-detects fastest available backend at startup)
# - auto: Automatically selects the fastest backend (recommended)
# - eager: Standard PyTorch attention (baseline, slowest)
# - sdpa: Scaled Dot Product Attention (PyTorch built-in, good performance)
# - flash_attention_2: Optimized with FlashAttention 2 (fastest, requires flash-attn)
# Install flash-attn for maximum performance: pip install flash-attn --no-build-isolation
ATTENTION_BACKEND=auto

# Default model size for OpenAI-compatible aliases
# Options: small (0.6B), large (1.7B)
# Default: small
# Note: Small models use ~4GB VRAM, large models use ~8GB VRAM
DEFAULT_MODEL_SIZE=small

# ============================================
# Cleanup Settings
# ============================================

# Enable automatic cleanup of idle models
# Options: true, false
# Default: true
CLEANUP_ENABLED=true

# Seconds between cleanup checks
# Default: 60
# Lower values = more frequent cleanup but slightly higher CPU usage
CLEANUP_INTERVAL=60

# ============================================
# Model Paths (optional)
# ============================================
# Only set these if you want to override default paths
# All paths are relative to project root unless absolute

# Small models (0.6B)
# BASE_MODEL_PATH=models/base
# CUSTOM_VOICE_MODEL_PATH=models/custom-voice
# VOICE_DESIGN_MODEL_PATH=models/voice-design

# Large models (1.7B)
# BASE_LARGE_MODEL_PATH=models/base-large
# CUSTOM_VOICE_LARGE_MODEL_PATH=models/custom-voice-large

# Tokenizer
# TOKENIZER_PATH=models/tokenizer

# ============================================
# Example Configurations
# ============================================

# Development (aggressive cleanup, small models)
# IDLE_TIMEOUT=60
# DEFAULT_MODEL_SIZE=small
# CLEANUP_ENABLED=true
# CLEANUP_INTERVAL=30

# Production High-Traffic (keep models loaded, large models)
# IDLE_TIMEOUT=1800
# DEFAULT_MODEL_SIZE=large
# CLEANUP_ENABLED=true
# CLEANUP_INTERVAL=300

# Low-Memory System (aggressive cleanup)
# IDLE_TIMEOUT=30
# DEFAULT_MODEL_SIZE=small
# CLEANUP_ENABLED=true
# CLEANUP_INTERVAL=15
